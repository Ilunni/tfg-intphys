{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"unet-segmentation.ipynb","provenance":[{"file_id":"19qLa6nFPOlHrA6l-tbaVOcfw-HpoOafr","timestamp":1590600517695}],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1pJKTwE3bsAIsToLm3sI5s2Da_XJmXamu","authorship_tag":"ABX9TyNP9Fmk8IaLnQHLNPaUUpqg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"abJ4Sj6GXoH8","colab_type":"code","colab":{}},"source":["# System libraries.\n","import os\n","import sys\n","\n","# Change working directory to Colab Notebooks.\n","%cd \"/content/drive/My Drive/Colab/\"\n","\n","# Import my modules.\n","sys.path.append(\"./modules\")\n","from train_unet_seg import train_unet_image2seg_object\n","\n","loss_name = \"entropy_dice\"\n","block_list = [13,14,15]\n","\n","for block_number in block_list:\n","\n","    num_scenes = 1000\n","    epochs = 3\n","    learning_rate = False\n","\n","    if block_number == 1:\n","        \n","        model_loading = False\n","        load_loss_name = \"entropy_dice\"\n","        load_block_number = block_number - 1\n","\n","    else:    \n","        \n","        model_loading = True\n","        load_loss_name = \"entropy_dice\"\n","        load_block_number = block_number - 1\n","\n","    model_summary = True\n","    check_partition = False\n","    \n","    cloud_storage = False\n","    test = False\n","\n","    if cloud_storage:\n","\n","        block_name = \"{:02}\".format(block_number)\n","\n","        if not os.path.isfile(\"/content/temp_dataset/dataset-intphys-{}000.hdf5\".format(block_name)): \n","        \n","            from google.colab import auth\n","            auth.authenticate_user()\n","            project_id = 'intphys'\n","            bucket_name = 'datasets-intphys'\n","            !gcloud config set project {project_id}\n","            !gsutil cp gs://{bucket_name}/dataset-intphys-{block_name}000.hdf5 /content/temp_dataset/dataset-intphys-{block_name}000.hdf5\n","\n","    elif test:\n","        !mkdir /content/temp_dataset\n","        !cp dataset/dataset-intphys-test.hdf5 /content/temp_dataset\n","        \n","    model = train_unet_image2seg_object(loss_name, \n","                                        block_number, \n","                                        load_loss_name, \n","                                        load_block_number, \n","                                        num_scenes, \n","                                        epochs, \n","                                        learning_rate, \n","                                        model_loading, \n","                                        model_summary, \n","                                        check_partition)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QOwxBNm8n4TS","colab_type":"code","colab":{}},"source":["# System libraries.\n","import os\n","import sys\n","\n","# Change working directory to Colab Notebooks.\n","%cd \"/content/drive/My Drive/Colab/\"\n","\n","# Import my modules.\n","sys.path.append(\"./modules\")\n","from train_unet_seg import train_unet_image2seg_occlu\n","\n","loss_name = \"entropy_dice\"\n","block_list = [13,14,15]\n","\n","for block_number in block_list:\n","\n","    num_scenes = 1000\n","    epochs = 3\n","    learning_rate = False\n","\n","    if block_number == 1:\n","        \n","        model_loading = False\n","        load_loss_name = \"entropy_dice\"\n","        load_block_number = block_number - 1\n","\n","    else:    \n","        \n","        model_loading = True\n","        load_loss_name = \"entropy_dice\"\n","        load_block_number = block_number - 1\n","\n","    model_summary = False\n","    check_partition = False\n","    \n","    cloud_storage = True\n","    test = False\n","\n","    if cloud_storage:\n","\n","        block_name = \"{:02}\".format(block_number)\n","\n","        if not os.path.isfile(\"/content/temp_dataset/dataset-intphys-{}000.hdf5\".format(block_name)): \n","        \n","            from google.colab import auth\n","            auth.authenticate_user()\n","            project_id = 'intphys'\n","            bucket_name = 'datasets-intphys'\n","            !gcloud config set project {project_id}\n","            !gsutil cp gs://{bucket_name}/dataset-intphys-{block_name}000.hdf5 /content/temp_dataset/dataset-intphys-{block_name}000.hdf5\n","\n","    elif test:\n","        !mkdir /content/temp_dataset\n","        !cp dataset/dataset-intphys-test.hdf5 /content/temp_dataset\n","        \n","    model = train_unet_image2seg_occlu(loss_name, \n","                                       block_number, \n","                                       load_loss_name, \n","                                       load_block_number, \n","                                       num_scenes, \n","                                       epochs, \n","                                       learning_rate, \n","                                       model_loading, \n","                                       model_summary, \n","                                       check_partition)\n"],"execution_count":null,"outputs":[]}]}